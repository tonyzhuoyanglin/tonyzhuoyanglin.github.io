<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Improving Tennis Playing via AI Video Analysis</title>

    <meta name="description" content="Improving Tennis Playing via AI Video Analysis - A project that reconstructs 3D human motion from tennis video to enable quantitative comparisons between professional and regular players.">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://tonyzhuoyanglin.github.io/img/tennis_ai_rep.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://tonyzhuoyanglin.github.io/" />
    <meta property="og:title" content="Improving Tennis Playing via AI Video Analysis" />
    <meta property="og:description"
        content="This project reconstructs 3D human motion from tennis video using AI to enable quantitative comparisons between professional and regular players, helping improve tennis technique through advanced video analysis." />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Improving Tennis Playing via AI Video Analysis" />
    <meta name="twitter:description"
        content="This project reconstructs 3D human motion from tennis video using AI to enable quantitative comparisons between professional and regular players, helping improve tennis technique through advanced video analysis." />
    <meta name="twitter:image" content="https://tonyzhuoyanglin.github.io/img/tennis_ai_rep.jpg" />

    <meta http-equiv="origin-trial"
        content="AgTx0EwEo9k7FU+uQs2+KfM3RqolxyWv7ZRcs1cz0siAnvPde/MVEcQS61F6sCemUSj464Fi+nuEzUA/UeuJ6A0AAABheyJvcmlnaW4iOiJodHRwczovL3Rvbnl6aHVveWFuZ2xpbi5naXRodWIuaW86NDQzIiwiZmVhdHVyZSI6IldlYkdQVVN1Ymdyb3Vwc0ZlYXR1cmVzIiwiZXhwaXJ5IjoxNzQ0NzYxNTk5fQ==" />
    <!-- <link rel="icon" href="favicon.ico"> -->

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <!-- Google tag (gtag.js) - Replace with your own Google Analytics ID -->
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=YOUR_GA_ID"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'YOUR_GA_ID');
    </script> -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
    <script defer src="js/fontawesome.all.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.5.0/Chart.min.js"></script>

    <script src="js/app.js"></script>
    <script src="js/synced_video_selector.js"></script>

    <script type="module">
        import init, * as bindings from '/brush-demo/brush_app.js';
        const isWebGPUSupported = 'gpu' in navigator;
        const warningElement = document.getElementById('webgpu-warning');
        const canvasElement = document.getElementById('brush_canvas');

        const originalFocus = HTMLElement.prototype.focus;
        HTMLElement.prototype.focus = function () {
            if (!this.matches('[id="brush_canvas"]')) {
                originalFocus.apply(this, arguments);
            }
        };
        if (isWebGPUSupported) {
            const wasm = await init({ module_or_path: '/brush-demo/brush_app_bg.wasm' });

            window.wasmBindings = bindings;
            dispatchEvent(new CustomEvent("TrunkApplicationStarted", { detail: { wasm } }));
        } else {
            warningElement.style.display = 'block';
            canvasElement.style.display = 'none';
        }
    </script>

    <script type="module">
        import { setupCarousel } from "./js/splats.js"

        window.addEventListener("TrunkApplicationStarted", (e) => {
            // Load with an initial URL.
            var start_url = "https://storage.googleapis.com/realtime-nerf-360/cat4d/kling-forest-elf-fire_deform3dgs_pruned.ply"
            const app = new window.wasmBindings.EmbeddedApp("brush_canvas", `?zen=true`)
            window.app = app;
            // Loa
            loadViewer(start_url);
        });
    </script>

    <style>
        html {
            /* Remove touch delay: */
            touch-action: manipulation;
        }

        .final-element {
            white-space: nowrap;
        }

        .warning {
            background-color: #fff3cd;
            border-left: 4px solid #ffc107;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            color: #664d03;
            font-family: system-ui, -apple-system, sans-serif;
            margin: 1rem auto;
            max-width: 600px;
            padding: 1rem;
            text-align: left;
        }

        .warning-title {
            align-items: center;
            display: flex;
            font-size: 1.1rem;
            font-weight: 600;
            gap: 0.5rem;
            margin-bottom: 0.5rem;
        }

        .warning-title svg {
            height: 24px;
            width: 24px;
        }

        .warning-message {
            line-height: 1.5;
            margin: 0;
        }
    </style>
</head>


<body style="padding: 5%; padding-top: min(15px, 5%); padding-bottom: min(5px, 5%); width: 100%">
    <div class="container-lg text-center" style="max-width: 1500px; margin: auto;" id="main">
        <header role="banner">
            <!-- <div class="container" id="main"> -->
            <div class="row">
                <h2 class="col-md-12 text-center">
                    Improving Tennis Playing via AI Video Analysis<br>
                </h2>
            </div>
            <div class="row text-center">
                <div class="col-md-3">
                </div>
                <div class="container-fluid text-center">
                    <ul class="list-inline" style="white-space: nowrap; margin:0px 0px 0px 0px;">
                        <li><b>Zhuoyang (Tony) Lin</b></a></li>
                    </ul>
                </div>
                <div class="col-md-12 text-center" style="font-size: calc(min(3vw, 15px))">
                    Windermere Preparatory School
                </div>
                <!-- <div class="col-md-12 text-center" style="font-size: calc(min(3vw, 15px))">
                <b>NeurIPS 2024 (Oral)</b>
            </div> -->
            </div>
            <div class="row text-center">
                <span class="link-block" style="padding-top: 10px; padding-bottom: 10px">
                    <!-- <a href="gallery.html" class="external-link button is-normal is-rounded is-dark"
                        style="width: 120px; font-size: 15px">
                        <span>Gallery</span>
                    </a> -->
                </span>
            </div>
        </header>
        <br>
        <br>
        <main role="main">
            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <video id="teaser" width="100%" style="max-height: 600px; object-fit: contain;" autoplay loop muted controls
                        playsinline>
                        <source src="videos/overlay_forehand.mp4" type="video/mp4">
                        </source>
                        <!-- <source src="videos/teaser_top_inside.m4v" type="video/mp4"></source> -->
                    </video>
                </div>
            </div>
            <div class="row">
                <div class="col-md-8 offset-md-2 rounded"
                    style="text-align: center; padding-bottom: 0px; padding-top: 5px; background-color: #d0d5ec;">
                    <h6 style="text-align: center; color:rgb(0, 0, 0)"><strong>TL;DR</strong>:
                        This project reconstructs 3D human motion from video of tennis playing,
                        thereby enabling the quantitative comparisons between pro and regular players.</h6>
                </div>
            </div><br><br>

            <div class="row">
                <div class="">
                    <h3 class="col-md-8 offset-md-2"> How It Works </h3>
                    
                    <p class="col-md-8 offset-md-2" style="text-align: left; margin-bottom: 0px;">
                        We first downloaded videos of professional tennis playing and then trimmed these videos to the desired length,
                        covering only the strokes of interest. Next, we collected videos of me playing the same strokes and roughly trimmed to
                        the same length. We then extracted individual frames from both sets of videos, obtaining a time series of images for
                        each video.
                    </p>
                    <div style="display: flex; justify-content: center; gap: 20px; margin-top: 10px;">
                        <div style="text-align: center;">
                            <video style="height: 256px;" controls>
                                <source src="videos/how_it_works/forehand_pro.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <div style="margin-top: 5px;">Professional Player</div>
                        </div>
                        <div style="text-align: center;">
                            <video style="height: 256px;" controls>
                                <source src="videos/how_it_works/forehand_user.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <div style="margin-top: 5px;">Me Performing the Same Stroke</div>
                        </div>
                    </div>
                    <br>
                    <br>

                    <p class="col-md-8 offset-md-2" style="text-align: left; margin-bottom: 0px;">
                        With these time series of images, we applied HMR2 [Goel et al., 2023] to estimate, for each frame of the video, the 3D pose parameters of
                        the body. For context, HMR2 is a vision transformer-based neural network that takes as input a single image and outputs
                        the 3D pose parameters of the body (along with other shape parameters, which were not used here). We can then rig the SMPL
                        body model [Loper et al., 2015] with the pose parameters to obtain a time series of 3D meshes, which we render below.
                    </p>
                    <div style="display: flex; justify-content: center; gap: 20px; margin-top: 10px;">
                        <div style="text-align: center;">
                            <video style="height: 256px;" controls>
                                <source src="videos/how_it_works/pro_forehand_overlay_h264.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <div style="margin-top: 5px;">3D Reconstruction of the Professional Player</div>
                        </div>
                        <div style="text-align: center;">
                            <video style="height: 256px;" controls>
                                <source src="videos/how_it_works/user_forehand_overlay_h264.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <div style="margin-top: 5px;">3D Reconstruction of Me Performing the Same Stroke</div>
                        </div>
                    </div>
                    <br>
                    <br>

                    <p class="col-md-8 offset-md-2" style="text-align: left; margin-bottom: 0px;">
                        Since the body pose was estimated in the 3D space, we can render the 3D mesh from any viewpoint we want, different from the original
                        camera viewpoints as shown above. Below, we render the 3D human body from the top view to better understand the stroke in the 3D space.
                    </p>
                    <div style="display: flex; justify-content: center; gap: 20px; margin-top: 10px;">
                        <div style="text-align: center;">
                            <img style="height: 256px;" src="videos/how_it_works/pro_topdown.png" alt="Top-Down Rendering of the Professional Player">
                            <div style="margin-top: 5px;">Top-Down Rendering of the Professional Player</div>
                        </div>
                        <div style="text-align: center;">
                            <img style="height: 256px;" src="videos/how_it_works/user_topdown.png" alt="Top-Down Rendering of Me Performing the Same Stroke">
                            <div style="margin-top: 5px;">Top-Down Rendering of Me</div>
                        </div>
                    </div>
                    <br>
                    <br>

                    <p class="col-md-8 offset-md-2" style="text-align: left; margin-bottom: 0px;">
                        Furthermore, we can quantitatively analyze the differences in joint angles between the professional and me performing the same stroke,
                        since the pose parameters output by the neural network are rotation angles for all 23 joints. That said, the challenge is that the two videos
                        are not time-aligned; in other words, the joint angles at time <i>t</i> in the professional video are not comparable with those at time <i>t</i>
                        in the other video. To address this, we use Dynamic Time Warping (DTW) to align the two videos so that we time-align the joint angles,
                        and angles of the same joints at the same time are comparable between the two videos.
                        <br>
                        <br>
                        Below, we plot the difference heatmap of the joint angles between the professional and me performing the same stroke. Brigher colors
                        indicate bigger absolute angle differences. We focus on the first "comp1" column, which is the flexion of the angles
                        (for completeness, we also plot the abduction in the second column, even though we are not discussing it here).
                    </p>
                    <div style="display: flex; justify-content: center; gap: 20px; margin-top: 10px;">
                        <div style="text-align: center;">
                            <img style="height: 256px;" src="videos/how_it_works/fh_heatmap.png" alt="Joint Difference Heatmap">
                            <div style="margin-top: 5px;">Heatmap of Joint Angle Differences</div>
                        </div>
                    </div>
                    <br>
                    <br>
                    <p class="col-md-8 offset-md-2" style="text-align: left; margin-bottom: 0px;">
                        From the heatmap, we can see that the largest differences lie in the left and right knees, so we plot these joint angles over time for 
                        both players, shown below. From the plots, we can conclude that the professional player tends to have larger knee rotations for this stroke
                        -- consistent with both knees.
                    </p>
                    <div style="display: flex; justify-content: center; gap: 20px; margin-top: 10px;">
                        <div style="text-align: center;">
                            <img style="height: 256px;" src="videos/how_it_works/fh_Left_Knee.png" alt="Left Knee Angle Over Time">
                            <div style="margin-top: 5px;">Left Knee Angle Over Time</div>
                        </div>
                        <div style="text-align: center;">
                            <img style="height: 256px;" src="videos/how_it_works/fh_Right_Knee.png" alt="Right Knee Angle Over Time">
                            <div style="margin-top: 5px;">Right Knee Angle Over Time</div>
                        </div>
                    </div>
                    <br>
                    <br>
                    <p class="col-md-8 offset-md-2" style="text-align: left; margin-bottom: 0px;">
                        What about the smaller differences? We plot the joint angles of the left elbow. Indeed, both the professional player and I 
                        have similar elbow angles, indicating that I should work on my knee angles instead.
                    </p>
                    <div style="display: flex; justify-content: center; gap: 20px; margin-top: 10px;">
                        <div style="text-align: center;">
                            <img style="height: 256px;" src="videos/how_it_works/fh_Left_Elbow.png" alt="Left Elbow Angle Over Time">
                            <div style="margin-top: 5px;">Left Elbow Angle Over Time</div>
                        </div>
                    </div>
                </div>
            </div><br><br>


            <div class="row">
                <div class="">
                    <h3 class="col-md-8 offset-md-2"> Results </h3>
                </div>
                <p class="col-md-8 offset-md-2" style="text-align: left; margin-bottom: 0px;">
                   In this section, we first present a 4D interactive viewer, powered by <a
                   href="https://github.com/ArthurBrussee/brush">Brush</a>, that allows you to view the 3D human body from any viewpoint you want, across time.
                </p>

            <div id="viewer">
                <br>
                <div class="row">
                    <div class="col-md-8 offset-md-2 rounded card" style="background-color: #d0d5ec;">
                        <h3 style="text-align: center;">Interactive Viewer</h3>

                        <p class="text-center" style="text-align: center;">
                            Click on the images below to render 4D scenes in real-time in your browser!
                        </p>

                        <div id="webgpu-warning" style="display: none" class="warning">
                            <div class="warning-title">
                                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"
                                    stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"></circle>
                                    <path d="M12 8v5"></path>
                                    <circle cx="12" cy="16" r="0.5" fill="currentColor"></circle>
                                </svg>
                                Browser Not Supported
                            </div>
                            <p class="warning-message">
                                Your browser does not appear to support the interactive viewer. Currently, only Chrome
                                130+ is supported.
                            </p>
                        </div>


                        <canvas id="brush_canvas"
                            style="width: 100%; max-width:450px; aspect-ratio: 1/1; text-align:center; display: block; position: relative; margin-left: auto; margin-right: auto;"></canvas>

                        <div class="pill-row scene-pills" id="viewer-pills" role="group" aria-relevant="additions text">

                            <div class="pill scene-pill-large" data-value="genmo-coffee-machine">
                                <a
                                    onclick='loadViewer("https://storage.googleapis.com/realtime-nerf-360/cat4d/genmo-coffee-machine_deform3dgs_pruned.ply")'>
                                    <img class="card-img" src="videos/viewer_thumbnails/genmo-coffee-machine.png">
                                </a>
                            </div>


                            <div class="pill scene-pill-large" data-value="genmo-dog-holding-teddybear">
                                <a
                                    onclick='loadViewer("https://storage.googleapis.com/realtime-nerf-360/cat4d/genmo-dog-holding-teddybear_deform3dgs_pruned.ply")'>
                                    <img class="card-img"
                                        src="videos/viewer_thumbnails/genmo-dog-holding-teddybear.png">
                                </a>
                            </div>

                            <!--
                            <div class="splat-carousel position-relative" id="splat-carousel" role="group"
                                aria-relevant="additions text">
                                <div class="splat-carousel-items">
                                    <div id="splat-carousel-prototype">
                                        <div class="splat-carousel-item">
                                            <img class="card-img"
                                                style="user-drag: none;pointer-events: none; user-select:none;" src="">
                                        </div>
                                    </div>
                                </div>

                                <div class="splat-carousel-buttons">
                                    <button class="splat-carousel-button left">&#8249;</button>
                                    <button class="splat-carousel-button right">&#8250;</button>
                                </div>
                            </div> -->
                        </div>
                    </div>
                </div>
                <br><br>

                <script>
                    compareDiv = document.querySelector("#cameratime-ours")
                    activeScene_cameratime = "wt0000"

                    const methodPills_cameratime = compareDiv.querySelectorAll('.method-pill');
                    const scenePills_cameratime = compareDiv.querySelectorAll(".scene-pill")
                    const showVideo_cameratime = compareDiv.querySelector('#cameratime_ours_video')

                    for (scenePill of scenePills_cameratime) {
                        scenePill.addEventListener('click', function () {
                            activeScene_cameratime = this.getAttribute('data-value');
                            updateDisplayCameraTime();
                        });
                    }

                    function updateDisplayCameraTime() {
                        for (scenePill of scenePills_cameratime) {
                            if (scenePill.getAttribute('data-value') == activeScene_cameratime) {
                                scenePill.classList.add('active');
                            } else {
                                scenePill.classList.remove('active')
                            }
                        }
                        showVideo_cameratime.src = `videos/cameartime_ours/${activeScene_cameratime}.mp4`
                        showVideo_cameratime.playbackRate = 2.0;
                    }
                    // Update initial display
                    updateDisplayCameraTime()

                </script>
            </div><br><br>

            <p class="col-md-8 offset-md-2" style="text-align: left; margin-bottom: 0px;">
                Here are more results from different videos.
             </p>

            <div class="row">
                <div class="col-md-8 offset-md-2">
                    <br>
                    <video id="backhand-video" width="100%" style="max-height: 600px; object-fit: contain;" autoplay loop muted controls
                        playsinline>
                        <source src="videos/results/overlay_compare_backhand.mp4" type="video/mp4">
                        </source>
                        <!-- <source src="videos/teaser_top_inside.m4v" type="video/mp4"></source> -->
                    </video>
                    <br>
                    <br>
                    <video id="serve-video" width="100%" style="max-height: 600px; object-fit: contain;" autoplay loop muted controls
                        playsinline>
                        <source src="videos/results/overlay_compare_serve.mp4" type="video/mp4">
                        </source>
                        <!-- <source src="videos/teaser_top_inside.m4v" type="video/mp4"></source> -->
                    </video>
                    <br>
                    <br>
                    <video id="volleyb-video" width="100%" style="max-height: 600px; object-fit: contain;" autoplay loop muted controls
                        playsinline>
                        <source src="videos/results/overlay_compare_volleyb.mp4" type="video/mp4">
                        </source>
                        <!-- <source src="videos/teaser_top_inside.m4v" type="video/mp4"></source> -->
                    </video>
                    <br>
                    <br>
                    <video id="volleyf-video" width="100%" style="max-height: 600px; object-fit: contain;" autoplay loop muted controls
                        playsinline>
                        <source src="videos/results/overlay_compare_volleyf.mp4" type="video/mp4">
                        </source>
                        <!-- <source src="videos/teaser_top_inside.m4v" type="video/mp4"></source> -->
                    </video>
                </div>
            </div>

            <div class="row">
                <div class="">
                    <br><br>
                    <h3 class="col-md-8 offset-md-2"> Next Steps </h3>
                    <p class="col-md-8 offset-md-2" style="text-align: left; margin-bottom: 0px;">
                        The biggest limitations of the project are two-fold. I wish I would have the resources and time to explore these after enrolling in a university.
                        <br><br>
                        First, we used the pre-trained HMR2 model instead of training our own model.
                        While it makes little sense to train a model from scratch, we could have finetuned the pretrained model on tennis playing videos.
                        This is relatively challenging given the compute and labeling resources we have access to, so it was infeasible to produce a tennis
                        dataset for finetuning.
                        <br><br>
                        Second, the model is inherently per-frame, treating all frames independently without considering the video nature of the input data.
                        As such, the angles output by the model lack temporal consistency. While one can apply smoothing techniques like Slerp to smooth 
                        the angles, the ideal solution would be adapting the HMR2 model to a video model that jointly considers all frames properly and outputs
                        smooth and accurate angles.
                       
                    </p>
                </div>
            </div>

             <div class="row">
                 <div class="">
                    <br><br>
                     <h3 class="col-md-8 offset-md-2"> References </h3>
                     <div class="col-md-8 offset-md-2">
                         <table class="table table-bordered" style="text-align: left; margin-bottom: 0px;">
                             <tbody>
                                 <tr>
                                     <td>Goel et al., 2023</td>
                                     <td>
                                         Shubham Goel, Georgios Pavlakos, Jathushan Rajasegaran, Angjoo Kanazawa, Jitendra Malik.<br>
                                         <b>Humans in 4D: Reconstructing and Tracking Humans with Transformers.</b><br>
                                         International Conference on Computer Vision (ICCV), 2023.
                                     </td>
                                 </tr>
                                 <tr>
                                     <td>Loper et al., 2015</td>
                                     <td>
                                        Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, Michael J. Black<br>
                                         <b>SMPL: A Skinned Multi-Person Linear Model.</b><br>
                                         ACM Trans. Graphics (Proc. SIGGRAPH Asia), 2015.
                                     </td>
                                 </tr>
                             </tbody>
                         </table>
                     </div>
                 </div>
             </div>
        </main>
        
        <footer>
            <div class="row">
                <div class="col-md-8 offset-md-2 text-center">
                    <br><br>
                    <br><br>
                    <p class="text-justify" style="text-align: center;">
                        <i>
						    Website modified from <a href="https://cat-4d.github.io">CAT4D</a>
                        </i>
                    </p>
                </div>
            </div>

        </footer>
    </div>
</body>

</html>
